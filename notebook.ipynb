{"cells":[{"source":"# Practical Exam: House sales\n\nRealAgents is a real estate company that focuses on selling houses.\n\nRealAgents sells a variety of types of house in one metropolitan area.\n\nSome houses sell slowly and sometimes require lowering the price in order to find a buyer.\n\nIn order to stay competitive, RealAgents would like to optimize the listing prices of the houses it is trying to sell.\n\nThey want to do this by predicting the sale price of a house given its characteristics.\n\nIf they can predict the sale price in advance, they can decrease the time to sale.\n\n\n## Data\n\nThe dataset contains records of previous houses sold in the area.\n\n| Column Name | Criteria                                                |\n|-------------|---------------------------------------------------------|\n| house_id    | Nominal. </br> Unique identifier for houses. </br>Missing values not possible. |\n| city        | Nominal. </br>The city in which the house is located. One of 'Silvertown', 'Riverford', 'Teasdale' and 'Poppleton'. </br>Replace missing values with \"Unknown\". |\n| sale_price  | Discrete. </br>The sale price of the house in whole dollars. Values can be any positive number greater than or equal to zero.</br>Remove missing entries. |\n| sale_date   | Discrete. </br>The date of the last sale of the house. </br>Replace missing values with 2023-01-01. |\n| months_listed  | Continuous. </br>The number of months the house was listed on the market prior to its last sale, rounded to one decimal place. </br>Replace missing values with mean number of months listed, to one decimal place. |\n| bedrooms    | Discrete. </br>The number of bedrooms in the house. Any positive values greater than or equal to zero. </br>Replace missing values with the mean number of bedrooms, rounded to the nearest integer. |\n| house_type   | Ordinal. </br>One of \"Terraced\" (two shared walls), \"Semi-detached\" (one shared wall), or \"Detached\" (no shared walls). </br>Replace missing values with the most common house type. |\n| area      | Continuous. </br>The area of the house in square meters, rounded to one decimal place. </br>Replace missing values with the mean, to one decimal place. |\n","metadata":{},"id":"e33eda06-7d7d-445e-8cd0-60b4d4b13afb","cell_type":"markdown"},{"source":"# Task 1\n\nThe team at RealAgents knows that the city that a property is located in makes a difference to the sale price. \n\nUnfortuntately they believe that this isn't always recorded in the data. \n\nCalculate the number of missing values of the `city`. \n\n - You should use the data in the file \"house_sales.csv\". \n\n - Your output should be an object `missing_city`, that contains the number of missing values in this column. ","metadata":{},"id":"ce597564-6bd3-4f54-830b-d5bac083c04a","cell_type":"markdown"},{"source":"# Use this cell to write your code for Task 1\nimport pandas as pd\nimport numpy as np\ndf = pd.read_csv('house_sales.csv')\nmissing_city = (df['city']=='--').sum()\nprint(missing_city)","metadata":{"executionCancelledAt":null,"executionTime":19,"lastExecutedAt":1764502824378,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Use this cell to write your code for Task 1\nimport pandas as pd\nimport numpy as np\ndf = pd.read_csv('house_sales.csv')\nmissing_city = (df['city']=='--').sum()\nprint(missing_city)","lastExecutedByKernel":"52b7a7b8-c015-4ab4-a1fa-cd1e14fbe8a6","outputsMetadata":{"0":{"height":38,"type":"stream"}}},"id":"b2cb73bf-bb81-4664-b3eb-c35f6914a652","cell_type":"code","execution_count":159,"outputs":[{"output_type":"stream","name":"stdout","text":"73\n"}]},{"source":"# Task 2 \n\nBefore you fit any models, you will need to make sure the data is clean. \n\nThe table below shows what the data should look like. \n\nCreate a cleaned version of the dataframe. \n\n - You should start with the data in the file \"house_sales.csv\". \n\n - Your output should be a dataframe named `clean_data`. \n\n - All column names and values should match the table below.\n\n\n| Column Name | Criteria                                                |\n|-------------|---------------------------------------------------------|\n| house_id    | Nominal. </br> Unique identifier for houses. </br>Missing values not possible. |\n| city        | Nominal. </br>The city in which the house is located. One of 'Silvertown', 'Riverford', 'Teasdale' and 'Poppleton' </br>Replace missing values with \"Unknown\". |\n| sale_price  | Discrete. </br>The sale price of the house in whole dollars. Values can be any positive number greater than or equal to zero.</br>Remove missing entries. |\n| sale_date   | Discrete. </br>The date of the last sale of the house. </br>Replace missing values with 2023-01-01. |\n| months_listed  | Continuous. </br>The number of months the house was listed on the market prior to its last sale, rounded to one decimal place. </br>Replace missing values with mean number of months listed, to one decimal place. |\n| bedrooms    | Discrete. </br>The number of bedrooms in the house. Any positive values greater than or equal to zero. </br>Replace missing values with the mean number of bedrooms, rounded to the nearest integer. |\n| house_type   | Ordinal. </br>One of \"Terraced\", \"Semi-detached\", or \"Detached\". </br>Replace missing values with the most common house type. |\n| area      | Continuous. </br>The area of the house in square meters, rounded to one decimal place. </br>Replace missing values with the mean, to one decimal place. |","metadata":{},"id":"5045c039-b353-46ba-87b9-af63aaa4abf3","cell_type":"markdown"},{"source":"clean_data.info()\ndf.info()","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1764502824429,"lastExecutedByKernel":"52b7a7b8-c015-4ab4-a1fa-cd1e14fbe8a6","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"clean_data.info()\ndf.info()","outputsMetadata":{"0":{"height":593,"type":"stream"},"1":{"height":50,"type":"dataFrame","tableState":{"customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"41f16b57-3671-4dde-b3cf-fa52dec50778","nodeType":"const"}}}}},"cell_type":"code","id":"635d8b92-3cb5-46d8-9d6c-afbe8b4a6c6f","outputs":[{"output_type":"stream","name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1500 entries, 0 to 1499\nData columns (total 8 columns):\n #   Column         Non-Null Count  Dtype         \n---  ------         --------------  -----         \n 0   house_id       1500 non-null   category      \n 1   city           1500 non-null   category      \n 2   sale_price     1500 non-null   int64         \n 3   sale_date      1500 non-null   datetime64[ns]\n 4   months_listed  1500 non-null   float64       \n 5   bedrooms       1500 non-null   int64         \n 6   house_type     1500 non-null   category      \n 7   area           1500 non-null   float64       \ndtypes: category(3), datetime64[ns](1), float64(2), int64(2)\nmemory usage: 108.9 KB\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1500 entries, 0 to 1499\nData columns (total 8 columns):\n #   Column         Non-Null Count  Dtype  \n---  ------         --------------  -----  \n 0   house_id       1500 non-null   int64  \n 1   city           1500 non-null   object \n 2   sale_price     1500 non-null   int64  \n 3   sale_date      1500 non-null   object \n 4   months_listed  1469 non-null   float64\n 5   bedrooms       1500 non-null   int64  \n 6   house_type     1500 non-null   object \n 7   area           1500 non-null   object \ndtypes: float64(1), int64(3), object(4)\nmemory usage: 93.9+ KB\n"}],"execution_count":160},{"source":"# Use this cell to write your code for Task 2\nimport pandas as pd\nimport numpy as np\nclean_data = pd.read_csv('house_sales.csv')\n\n#Update area Column\nclean_data['area'] = clean_data['area'].str.replace('sq.m.','')\nclean_data['area'] = pd.to_numeric(clean_data['area'], errors='coerce')\n# Replace missing with mean, rounded to one decimal place.\nfill_value_area = round(clean_data['area'].mean(), 1)\nclean_data['area'].fillna(fill_value_area, inplace=True)\nclean_data['area'] = clean_data['area'].round(1).astype('float64')\n\n#updat sale price column\nclean_data.dropna(subset=['sale_price'], inplace=True)\nclean_data['sale_price'] = clean_data['sale_price'].astype('int64')\n\n#Update House ID column\nclean_data['house_id'] = clean_data['house_id'].astype('category')\n\n#Clean City Column\nvalid_cities = ['Silvertown', 'Riverford', 'Teasdale', 'Poppleton']\nclean_data['city'] = clean_data['city'].apply(lambda x: x if x in valid_cities else 'Unknown')\nclean_data['city'] = clean_data['city'].astype('category')\n\n# Clean Sales Date column\nclean_data['sale_date'] = pd.to_datetime(clean_data['sale_date'], errors='coerce')\nclean_data['sale_date'].fillna(pd.to_datetime('2023-01-01'), inplace=True)\n\n# Clean Month Listed column\nfill_value_months = round(clean_data['months_listed'].mean(), 1)\nclean_data['months_listed'].fillna(fill_value_months, inplace=True)\nclean_data['months_listed'] = clean_data['months_listed'].round(1).astype('float64')\n\n# Clean bedrooms column\nfill_value_bedrooms = round(clean_data['bedrooms'].mean())\nclean_data['bedrooms'].replace({np.nan: fill_value_bedrooms}, inplace=True)\nclean_data['bedrooms'] = clean_data['bedrooms'].astype('int64')\n\n# Clean House type\n\ntype_mapping = {\n    'Det.': 'Detached',\n    'Semi': 'Semi-detached',\n    'Terr.': 'Terraced'\n    \n}\n\n\nclean_data['house_type'].replace(type_mapping, inplace=True)\n\n\nmode_house_type = clean_data['house_type'].mode()[0]\nclean_data['house_type'].fillna(mode_house_type, inplace=True)\n\n\nclean_data['house_type'] = pd.Categorical(\n    clean_data['house_type'],\n    categories=[\"Terraced\", \"Semi-detached\", \"Detached\"],\n    ordered=True\n)\n\nclean_data.head()","metadata":{"executionCancelledAt":null,"executionTime":68,"lastExecutedAt":1764502824497,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Use this cell to write your code for Task 2\nimport pandas as pd\nimport numpy as np\nclean_data = pd.read_csv('house_sales.csv')\n\n#Update area Column\nclean_data['area'] = clean_data['area'].str.replace('sq.m.','')\nclean_data['area'] = pd.to_numeric(clean_data['area'], errors='coerce')\n# Replace missing with mean, rounded to one decimal place.\nfill_value_area = round(clean_data['area'].mean(), 1)\nclean_data['area'].fillna(fill_value_area, inplace=True)\nclean_data['area'] = clean_data['area'].round(1).astype('float64')\n\n#updat sale price column\nclean_data.dropna(subset=['sale_price'], inplace=True)\nclean_data['sale_price'] = clean_data['sale_price'].astype('int64')\n\n#Update House ID column\nclean_data['house_id'] = clean_data['house_id'].astype('category')\n\n#Clean City Column\nvalid_cities = ['Silvertown', 'Riverford', 'Teasdale', 'Poppleton']\nclean_data['city'] = clean_data['city'].apply(lambda x: x if x in valid_cities else 'Unknown')\nclean_data['city'] = clean_data['city'].astype('category')\n\n# Clean Sales Date column\nclean_data['sale_date'] = pd.to_datetime(clean_data['sale_date'], errors='coerce')\nclean_data['sale_date'].fillna(pd.to_datetime('2023-01-01'), inplace=True)\n\n# Clean Month Listed column\nfill_value_months = round(clean_data['months_listed'].mean(), 1)\nclean_data['months_listed'].fillna(fill_value_months, inplace=True)\nclean_data['months_listed'] = clean_data['months_listed'].round(1).astype('float64')\n\n# Clean bedrooms column\nfill_value_bedrooms = round(clean_data['bedrooms'].mean())\nclean_data['bedrooms'].replace({np.nan: fill_value_bedrooms}, inplace=True)\nclean_data['bedrooms'] = clean_data['bedrooms'].astype('int64')\n\n# Clean House type\n\ntype_mapping = {\n    'Det.': 'Detached',\n    'Semi': 'Semi-detached',\n    'Terr.': 'Terraced'\n    \n}\n\n\nclean_data['house_type'].replace(type_mapping, inplace=True)\n\n\nmode_house_type = clean_data['house_type'].mode()[0]\nclean_data['house_type'].fillna(mode_house_type, inplace=True)\n\n\nclean_data['house_type'] = pd.Categorical(\n    clean_data['house_type'],\n    categories=[\"Terraced\", \"Semi-detached\", \"Detached\"],\n    ordered=True\n)\n\nclean_data.head()","lastExecutedByKernel":"52b7a7b8-c015-4ab4-a1fa-cd1e14fbe8a6","outputsMetadata":{"0":{"height":500,"type":"dataFrame","tableState":{}}}},"id":"dc9c2344-a350-461c-b5db-40768b2165a5","cell_type":"code","execution_count":161,"outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"house_id","type":"any","constraints":{"enum":[1000296,1001618,1004244,1004906,1005837,1006587,1007511,1008985,1009325,1010031,1010355,1010498,1010801,1010812,1011982,1012593,1013721,1014145,1014495,1014739,1016104,1017461,1018165,1018486,1018876,1019238,1019689,1021690,1022222,1023229,1024283,1025825,1027136,1027380,1027849,1028100,1028805,1029340,1029841,1030063,1030379,1031796,1032687,1032788,1032875,1033640,1033968,1034402,1034795,1035135,1035550,1035958,1036834,1036836,1037459,1037495,1037597,1037981,1040638,1040647,1041659,1042443,1042506,1044679,1045210,1045300,1045313,1045551,1046302,1046910,1047506,1047819,1048707,1048748,1049091,1049200,1049250,1049580,1050073,1050654,1051195,1051241,1051344,1053077,1057028,1058044,1058161,1058813,1060270,1060994,1062533,1063784,1064065,1064136,1064516,1064698,1064901,1065281,1066388,1066607,1066669,1067312,1067695,1068668,1069572,1069910,1070852,1071136,1071778,1071798,1072523,1073244,1073648,1074831,1075564,1075629,1075964,1076011,1076417,1078394,1079746,1081697,1084396,1086971,1089831,1090445,1091146,1091914,1092241,1093115,1094153,1094616,1094683,1094843,1095534,1095867,1096215,1096258,1096726,1097108,1098103,1099156,1099364,1099961,1100407,1101259,1102880,1103196,1103870,1104838,1105017,1105394,1107132,1110512,1111858,1111911,1112585,1112630,1112795,1112926,1113820,1115973,1117348,1117876,1118440,1120502,1120760,1121170,1121226,1121506,1122070,1122377,1123892,1124211,1124567,1124806,1124893,1124935,1124949,1125223,1127386,1127688,1127944,1128031,1130002,1130844,1130933,1132548,1132814,1133211,1133435,1133447,1135020,1135470,1136950,1137000,1137705,1138096,1138391,1139390,1139708,1139840,1140256,1140298,1140466,1140952,1144529,1144804,1145723,1146287,1146564,1147303,1147990,1149032,1149299,1150212,1150869,1150963,1151354,1152072,1152822,1153743,1155864,1155893,1159201,1159626,1159691,1160478,1160936,1161250,1161276,1161942,1163990,1164142,1166157,1166868,1166911,1167348,1167858,1168631,1168990,1169444,1169460,1170602,1170760,1171557,1171582,1171830,1171863,1173096,1173813,1174758,1174927,1175659,1176007,1176419,1176545,1176623,1176670,1176745,1178486,1179393,1179477,1179940,1179949,1180611,1181342,1182802,1182916,1183122,1183553,1186022,1186664,1187498,1188073,1189017,1189566,1189929,1191967,1194038,1194375,1195530,1196565,1197355,1200264,1202901,1203285,1203325,1204470,1205231,1207020,1207578,1208439,1208983,1209442,1210299,1211594,1212300,1214267,1215254,1215812,1216336,1216397,1217792,1218910,1219851,1221595,1221789,1221856,1222170,1222880,1223416,1223765,1224266,1224317,1224962,1225109,1226316,1226541,1226868,1227304,1229099,1229417,1230049,1230399,1230625,1232228,1232992,1233422,1233627,1233689,1234374,1234703,1235265,1235337,1236200,1236347,1236600,1237166,1237280,1237673,1237950,1239607,1240644,1241963,1242333,1243395,1243789,1244583,1245207,1245466,1245803,1245874,1245960,1246701,1246779,1247170,1248329,1249429,1249631,1249804,1250128,1250132,1250149,1251587,1252193,1253152,1253220,1253695,1256263,1256594,1257849,1258196,1258274,1258487,1259142,1259632,1260544,1261071,1261270,1261658,1262675,1263772,1264788,1265706,1265876,1265998,1266714,1267290,1267302,1267799,1268037,1268745,1269238,1269355,1269475,1270480,1270531,1271940,1272848,1273651,1273854,1274479,1276605,1277089,1278608,1279074,1281028,1281064,1281420,1281449,1281734,1281890,1282303,1282336,1283579,1284190,1285719,1285895,1286417,1286904,1286998,1287690,1287962,1289056,1289493,1289616,1290077,1290297,1291189,1293497,1293594,1293951,1294049,1295524,1296099,1298078,1298353,1298355,1299166,1299198,1300327,1300404,1301257,1301616,1302367,1303283,1303692,1306187,1306326,1307040,1307813,1308034,1308577,1309502,1309830,1310526,1310746,1312145,1312507,1313150,1313426,1314027,1314840,1315287,1316360,1316807,1317186,1317783,1318295,1318782,1319066,1319650,1320300,1320704,1322729,1324648,1325825,1326085,1327295,1328607,1328789,1328828,1328959,1329438,1330040,1330277,1331225,1332844,1333241,1333860,1334358,1334580,1334966,1336202,1338077,1339548,1340649,1341975,1342593,1342820,1345063,1345078,1345608,1345926,1346945,1347376,1348687,1349895,1350280,1351812,1351828,1352580,1353069,1353946,1354601,1356331,1356336,1357211,1357314,1357975,1358048,1358710,1358764,1359697,1360173,1360641,1360687,1360727,1361643,1362207,1364727,1364811,1364988,1365938,1366380,1366738,1367339,1368561,1368878,1369220,1370378,1373181,1373696,1375107,1375134,1375644,1375835,1377013,1377544,1378910,1380656,1382132,1382549,1383244,1383706,1384054,1384509,1385300,1386198,1386213,1386473,1388891,1388933,1389000,1390723,1390771,1390884,1393237,1393254,1395143,1395988,1396614,1398077,1400177,1400196,1401538,1401675,1402511,1402660,1403013,1403039,1403439,1405097,1405523,1406027,1406280,1407264,1407524,1407557,1407703,1408410,1408896,1409662,1409940,1410579,1410650,1411516,1411597,1412299,1412586,1414175,1414501,1415208,1415530,1416044,1416637,1418266,1418313,1418441,1418816,1419111,1421023,1421393,1421698,1421799,1422210,1422349,1422432,1422449,1422937,1422971,1423130,1423337,1424107,1424659,1426605,1427886,1429619,1429810,1431144,1432040,1433252,1435028,1435319,1435410,1436257,1436311,1437188,1437921,1438302,1438805,1438855,1439034,1440226,1440583,1440796,1441365,1442229,1442800,1442937,1443538,1444776,1446830,1447466,1448331,1448472,1448500,1448759,1450091,1450270,1450742,1451623,1451857,1454970,1455120,1456035,1457793,1458307,1458688,1458707,1458817,1459825,1459954,1460636,1461222,1461323,1462292,1462313,1462894,1463399,1463861,1464675,1464727,1466345,1466804,1466880,1467017,1468812,1468987,1470021,1471399,1471465,1472163,1472353,1472753,1472754,1472802,1473010,1473953,1474508,1475202,1476754,1477196,1477649,1479094,1480021,1480243,1480556,1481658,1481777,1481909,1482499,1482978,1482995,1483175,1483706,1486534,1486915,1487089,1487508,1487654,1487718,1488937,1489036,1489487,1491590,1491632,1491743,1491804,1492089,1493721,1493815,1497976,1499211,1499712,1500060,1500725,1500771,1501985,1502114,1502203,1504371,1505538,1506579,1506704,1507065,1507614,1508452,1509081,1509334,1509394,1509587,1509752,1509984,1510070,1510857,1510886,1510942,1511093,1512144,1512484,1512919,1513003,1513415,1513609,1513904,1514204,1514297,1515009,1516889,1517850,1518604,1518925,1519372,1519539,1519704,1520725,1520781,1521271,1522263,1522375,1524452,1524475,1525711,1525754,1526063,1526513,1527410,1527872,1528234,1528991,1529229,1529311,1529751,1530646,1531316,1533230,1534182,1535326,1535520,1536822,1536829,1537409,1537754,1539789,1541723,1542453,1542454,1542591,1542650,1542713,1543604,1544469,1545161,1545295,1545670,1546532,1547654,1547826,1548177,1548631,1548850,1549413,1549639,1549655,1549920,1550067,1550735,1550941,1551901,1552013,1552267,1552531,1552726,1553108,1553504,1554766,1555650,1556095,1556467,1556577,1556675,1558240,1560595,1560933,1561565,1562788,1562955,1563097,1563589,1563994,1564018,1564132,1564205,1564211,1565022,1566683,1567024,1567056,1567991,1568591,1569660,1569966,1570368,1570453,1571579,1572330,1573142,1573560,1573891,1575047,1576185,1576622,1577275,1577989,1578473,1578801,1579084,1579125,1580068,1580468,1580529,1580905,1582462,1582571,1582785,1583062,1583370,1584947,1585100,1585230,1586352,1586625,1587710,1589535,1589593,1589617,1590335,1591027,1591145,1592779,1592992,1594333,1594453,1594921,1596659,1597975,1598280,1598892,1598909,1599167,1599848,1599868,1600307,1600359,1600913,1601250,1601956,1604508,1605792,1606424,1607640,1608672,1608726,1608791,1611591,1612349,1612365,1614278,1617244,1618694,1618764,1618772,1618928,1619080,1619232,1619876,1620118,1622041,1622761,1623206,1624270,1624288,1624380,1624736,1625589,1625823,1625844,1626141,1626381,1626594,1627678,1627838,1629059,1629610,1629642,1631243,1632453,1633185,1633532,1635060,1635137,1635197,1635218,1635707,1637981,1637988,1639742,1640403,1641603,1641816,1643636,1643856,1643896,1644080,1644786,1644934,1645820,1645993,1646556,1646721,1647410,1648119,1649002,1650088,1650856,1652149,1653992,1655164,1655586,1656047,1656422,1657233,1657359,1658159,1658810,1659623,1659651,1659767,1660160,1661975,1662312,1662358,1663573,1663993,1664271,1664309,1664399,1664425,1664607,1665042,1665407,1665493,1665513,1665547,1665574,1666848,1667394,1668109,1668276,1668445,1669244,1669460,1669743,1669937,1670040,1670747,1672014,1672551,1672733,1673726,1674021,1674075,1676562,1677755,1679022,1679272,1680108,1680567,1680805,1682594,1682963,1683098,1683152,1683219,1683570,1685299,1685455,1685700,1686480,1686564,1687723,1687847,1688040,1688219,1688352,1689970,1690505,1690740,1691248,1692792,1693374,1693997,1694974,1696742,1697785,1698278,1698956,1699228,1699343,1699422,1699880,1699887,1700474,1702443,1702505,1702512,1703153,1704391,1704676,1705357,1707034,1708954,1708987,1709120,1710056,1710057,1710155,1710617,1710916,1710943,1711579,1712095,1714130,1715748,1718392,1719139,1719924,1719944,1720010,1720211,1721740,1721933,1722310,1722437,1722765,1722810,1723878,1724396,1725497,1726453,1727493,1728821,1729121,1729386,1730020,1731052,1731309,1731318,1732469,1733693,1734155,1734425,1734487,1734849,1735694,1736280,1736423,1737414,1737725,1737825,1738352,1738515,1740928,1742084,1742630,1743161,1743394,1744369,1745475,1745950,1746052,1746490,1748617,1749657,1749742,1750679,1751441,1751885,1752476,1752479,1752654,1753061,1753791,1755042,1755905,1755997,1757054,1757147,1757253,1758049,1758416,1758719,1759657,1760892,1762638,1762846,1763175,1764310,1764460,1766923,1769256,1771835,1772362,1773666,1774226,1774951,1776487,1777242,1778053,1778709,1780975,1781744,1783178,1783843,1784112,1784296,1784355,1785391,1788006,1788752,1789270,1789755,1790132,1791043,1791897,1798125,1800459,1800861,1803049,1803126,1803386,1803730,1804281,1804728,1805319,1805685,1805787,1806013,1806448,1806912,1807631,1807732,1807802,1808939,1809998,1810420,1810913,1811243,1811893,1813952,1814426,1814706,1816356,1816606,1817042,1818481,1819804,1820194,1821125,1821781,1822037,1823812,1825018,1825147,1826227,1828008,1828946,1829367,1829376,1831163,1833351,1833753,1833883,1834295,1834332,1834437,1835470,1835489,1835838,1836640,1836761,1838239,1839067,1840163,1840409,1840774,1841863,1842451,1843488,1843549,1844551,1845313,1845359,1846122,1847369,1848799,1848891,1849732,1849901,1850041,1850239,1850313,1850626,1851172,1851664,1852386,1855104,1855402,1855564,1856639,1857501,1857561,1857954,1858483,1860591,1860833,1860913,1861629,1862943,1862984,1864521,1864897,1865764,1865882,1866287,1866538,1867281,1867587,1867659,1867890,1868812,1869173,1869923,1870516,1871023,1871098,1871450,1872969,1873956,1875216,1875485,1876398,1876785,1877172,1877324,1877749,1879053,1879091,1879622,1880762,1881658,1882469,1882731,1882753,1883576,1883673,1883807,1883852,1884030,1884153,1884320,1885186,1885450,1885610,1886105,1886285,1886672,1886763,1886965,1887234,1887321,1888036,1889338,1889393,1889567,1891542,1891781,1892421,1892453,1892989,1895182,1896257,1896565,1897283,1897399,1897427,1900407,1900796,1900913,1903161,1903260,1905693,1907377,1908090,1908798,1910080,1910882,1910905,1911709,1911902,1911983,1913428,1913851,1914472,1914580,1914691,1915132,1915202,1915241,1915648,1915994,1916474,1917216,1917444,1918204,1919474,1919512,1919603,1920396,1921024,1922046,1922972,1923248,1923852,1924073,1924272,1924543,1924772,1924850,1924904,1925306,1925995,1926110,1927616,1927805,1928734,1929473,1929594,1930462,1930557,1930561,1932137,1932412,1933868,1935823,1936331,1937447,1937577,1937829,1938926,1939007,1939641,1940214,1940329,1941036,1941124,1941287,1941449,1942800,1943377,1943618,1944176,1944797,1945061,1947450,1948436,1948789,1948958,1949489,1949839,1950356,1950864,1952128,1953115,1953702,1953903,1954944,1957388,1957725,1958269,1960094,1960691,1960720,1960809,1961535,1962477,1967287,1967491,1967863,1969099,1970048,1972494,1974135,1975142,1976636,1977122,1977188,1978854,1980005,1981059,1981077,1981646,1982588,1983578,1985167,1985481,1987264,1987790,1988150,1988566,1988984,1990195,1991210,1991730,1991768,1992494,1992509,1993878,1994696,1995152,1995392,1995994,1997201,1997518,1998317,1998925,1999018,1999721]},"ordered":false},{"name":"city","type":"any","constraints":{"enum":["Poppleton","Riverford","Silvertown","Teasdale","Unknown"]},"ordered":false},{"name":"sale_price","type":"integer"},{"name":"sale_date","type":"datetime"},{"name":"months_listed","type":"number"},{"name":"bedrooms","type":"integer"},{"name":"house_type","type":"any","constraints":{"enum":["Terraced","Semi-detached","Detached"]},"ordered":true},{"name":"area","type":"number"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[0,1,2,3,4],"house_id":[1217792,1900913,1174927,1773666,1258487],"city":["Silvertown","Silvertown","Riverford","Silvertown","Silvertown"],"sale_price":[55943,384677,281707,373251,328885],"sale_date":["2021-09-12T00:00:00.000","2021-01-17T00:00:00.000","2021-11-10T00:00:00.000","2020-04-13T00:00:00.000","2020-09-24T00:00:00.000"],"months_listed":[5.4,6.3,6.9,6.1,8.7],"bedrooms":[2,5,6,6,5],"house_type":["Semi-detached","Detached","Detached","Detached","Detached"],"area":[107.8,498.8,542.5,528.4,477.1]}},"total_rows":5,"truncation_type":null},"text/plain":"  house_id        city  sale_price  ... bedrooms     house_type   area\n0  1217792  Silvertown       55943  ...        2  Semi-detached  107.8\n1  1900913  Silvertown      384677  ...        5       Detached  498.8\n2  1174927   Riverford      281707  ...        6       Detached  542.5\n3  1773666  Silvertown      373251  ...        6       Detached  528.4\n4  1258487  Silvertown      328885  ...        5       Detached  477.1\n\n[5 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>house_id</th>\n      <th>city</th>\n      <th>sale_price</th>\n      <th>sale_date</th>\n      <th>months_listed</th>\n      <th>bedrooms</th>\n      <th>house_type</th>\n      <th>area</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1217792</td>\n      <td>Silvertown</td>\n      <td>55943</td>\n      <td>2021-09-12</td>\n      <td>5.4</td>\n      <td>2</td>\n      <td>Semi-detached</td>\n      <td>107.8</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1900913</td>\n      <td>Silvertown</td>\n      <td>384677</td>\n      <td>2021-01-17</td>\n      <td>6.3</td>\n      <td>5</td>\n      <td>Detached</td>\n      <td>498.8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1174927</td>\n      <td>Riverford</td>\n      <td>281707</td>\n      <td>2021-11-10</td>\n      <td>6.9</td>\n      <td>6</td>\n      <td>Detached</td>\n      <td>542.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1773666</td>\n      <td>Silvertown</td>\n      <td>373251</td>\n      <td>2020-04-13</td>\n      <td>6.1</td>\n      <td>6</td>\n      <td>Detached</td>\n      <td>528.4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1258487</td>\n      <td>Silvertown</td>\n      <td>328885</td>\n      <td>2020-09-24</td>\n      <td>8.7</td>\n      <td>5</td>\n      <td>Detached</td>\n      <td>477.1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{"application/com.datacamp.data-table.v2+json":{"status":"success"}},"execution_count":161}]},{"source":"# Task 3 \n\nThe team at RealAgents have told you that they have always believed that the number of bedrooms is the biggest driver of house price. \n\nProducing a table showing the difference in the average sale price by number of bedrooms along with the variance to investigate this question for the team.\n\n - You should start with the data in the file 'house_sales.csv'.\n\n - Your output should be a data frame named `price_by_rooms`. \n\n - It should include the three columns `bedrooms`, `avg_price`, `var_price`. \n\n - Your answers should be rounded to 1 decimal place.   ","metadata":{},"id":"ff3c2889-66f3-4a6b-acac-2b12626e3244","cell_type":"markdown"},{"source":"# Use this cell to write your code for Task 3\ndf_3 = pd.read_csv('house_sales.csv')\nprice_by_rooms = df_3.groupby('bedrooms')['sale_price'].agg(['mean','var'])\nprice_by_rooms.columns = ['avg_price','var_price']\nprice_by_rooms = price_by_rooms.round(1)\nprice_by_rooms = price_by_rooms.reset_index()\nprice_by_rooms","metadata":{"executionCancelledAt":null,"executionTime":47,"lastExecutedAt":1764502824545,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Use this cell to write your code for Task 3\ndf_3 = pd.read_csv('house_sales.csv')\nprice_by_rooms = df_3.groupby('bedrooms')['sale_price'].agg(['mean','var'])\nprice_by_rooms.columns = ['avg_price','var_price']\nprice_by_rooms = price_by_rooms.round(1)\nprice_by_rooms = price_by_rooms.reset_index()\nprice_by_rooms","lastExecutedByKernel":"52b7a7b8-c015-4ab4-a1fa-cd1e14fbe8a6","outputsMetadata":{"0":{"height":550,"type":"dataFrame","tableState":{"customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"41f16b57-3671-4dde-b3cf-fa52dec50778","nodeType":"const"}}}}},"id":"ea512a1c-e512-4f2e-8d78-323e51d01407","cell_type":"code","execution_count":162,"outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"bedrooms","type":"integer"},{"name":"avg_price","type":"number"},{"name":"var_price","type":"number"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[0,1,2,3,4],"bedrooms":[2,3,4,5,6],"avg_price":[67076.4,154665.1,234704.6,301515.9,375741.3],"var_price":[565289569.7,2378289076.9,1725211191.5,2484327529,3924432279.5]}},"total_rows":5,"truncation_type":null},"text/plain":"   bedrooms  avg_price     var_price\n0         2    67076.4  5.652896e+08\n1         3   154665.1  2.378289e+09\n2         4   234704.6  1.725211e+09\n3         5   301515.9  2.484328e+09\n4         6   375741.3  3.924432e+09","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bedrooms</th>\n      <th>avg_price</th>\n      <th>var_price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>67076.4</td>\n      <td>5.652896e+08</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>154665.1</td>\n      <td>2.378289e+09</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>234704.6</td>\n      <td>1.725211e+09</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5</td>\n      <td>301515.9</td>\n      <td>2.484328e+09</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>375741.3</td>\n      <td>3.924432e+09</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{"application/com.datacamp.data-table.v2+json":{"status":"success"}},"execution_count":162}]},{"source":"# Task 4\n\nFit a baseline model to predict the sale price of a house.\n\n 1. Fit your model using the data contained in “train.csv” </br></br>\n\n 2. Use “validation.csv” to predict new values based on your model. You must return a dataframe named `base_result`, that includes `house_id` and `price`. The price column must be your predicted values.","metadata":{},"id":"ac7038d1-7a8f-4d97-aef1-36f3f1227374","cell_type":"markdown"},{"source":"# Use this cell to write your code for Task 4\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\n# --- Data Loading ---\ndf_train = pd.read_csv('train.csv')\ndf_test = pd.read_csv('validation.csv')\n\n# --- 1. Separate Target Variable ---\ny_train = df_train['sale_price']\nX_train = df_train.drop('sale_price', axis=1)\n\n# --- 2. Feature Engineering: Handle sale_date (The Fix) ---\n\ndef engineer_date_features(df):\n    # Convert to datetime object first (Errors='coerce' handles invalid dates)\n    df['sale_date'] = pd.to_datetime(df['sale_date'], errors='coerce')\n    \n    # Extract numerical features\n    df['sale_year'] = df['sale_date'].dt.year\n    df['sale_month'] = df['sale_date'].dt.month\n    \n    # Extract categorical feature (Day of Week)\n    df['sale_day_of_week'] = df['sale_date'].dt.day_name()\n    \n    # DROP the original high-cardinality 'sale_date' column\n    df = df.drop('sale_date', axis=1)\n    return df\n\nX_train_processed = engineer_date_features(X_train)\nX_test_processed = engineer_date_features(df_test.copy()) # Use a copy of df_test\n\n# --- 3. Handle Remaining Categorical Variables ---\n# Remaining categorical columns: 'city', 'house_type', and the new 'sale_day_of_week'\ncategorical_cols = ['city', 'house_type', 'sale_day_of_week']\n\n# Apply One-Hot Encoding to both training and test sets\nX_train_encoded = pd.get_dummies(X_train_processed, columns=categorical_cols, drop_first=True)\nX_test_encoded = pd.get_dummies(X_test_processed, columns=categorical_cols, drop_first=True)\n\n# Align columns to ensure both dataframes have the exact same features\nX_train_final, X_test_final = X_train_encoded.align(X_test_encoded, join='left', axis=1, fill_value=0)\n\n# Drop 'house_id' from the training set and remove any columns unique to the test set if alignment was outer/right\nX_train_final = X_train_final.drop('house_id', axis=1)\n\n# Prepare Test Set: Save house_id and drop it from features\nhouse_ids = X_test_final['house_id']\nX_test_final = X_test_final.drop('house_id', axis=1)\n# Handle potential NaN columns created during alignment (if test set was missing features)\nX_test_final = X_test_final.fillna(0) \n# Note: X_train_final will have NaN for columns missing in test, but since we align (join='left'),\n# only X_test_final will have NaN if train had extra columns, which we fill with 0.\n\n# --- 4. Model Fitting and Prediction ---\nlr = LinearRegression()\nlr.fit(X_train_final, y_train)\n\ny_pred = lr.predict(X_test_final)\n\n# --- 5. Final Output Creation ---\nbase_result = pd.DataFrame({\n    'house_id': house_ids,\n    'price': y_pred\n})\n\n\nprint(\"Successfully created 'base_result' with reduced feature set.\")","metadata":{"executionCancelledAt":null,"executionTime":73,"lastExecutedAt":1764502824618,"lastExecutedByKernel":"52b7a7b8-c015-4ab4-a1fa-cd1e14fbe8a6","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Use this cell to write your code for Task 4\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\n# --- Data Loading ---\ndf_train = pd.read_csv('train.csv')\ndf_test = pd.read_csv('validation.csv')\n\n# --- 1. Separate Target Variable ---\ny_train = df_train['sale_price']\nX_train = df_train.drop('sale_price', axis=1)\n\n# --- 2. Feature Engineering: Handle sale_date (The Fix) ---\n\ndef engineer_date_features(df):\n    # Convert to datetime object first (Errors='coerce' handles invalid dates)\n    df['sale_date'] = pd.to_datetime(df['sale_date'], errors='coerce')\n    \n    # Extract numerical features\n    df['sale_year'] = df['sale_date'].dt.year\n    df['sale_month'] = df['sale_date'].dt.month\n    \n    # Extract categorical feature (Day of Week)\n    df['sale_day_of_week'] = df['sale_date'].dt.day_name()\n    \n    # DROP the original high-cardinality 'sale_date' column\n    df = df.drop('sale_date', axis=1)\n    return df\n\nX_train_processed = engineer_date_features(X_train)\nX_test_processed = engineer_date_features(df_test.copy()) # Use a copy of df_test\n\n# --- 3. Handle Remaining Categorical Variables ---\n# Remaining categorical columns: 'city', 'house_type', and the new 'sale_day_of_week'\ncategorical_cols = ['city', 'house_type', 'sale_day_of_week']\n\n# Apply One-Hot Encoding to both training and test sets\nX_train_encoded = pd.get_dummies(X_train_processed, columns=categorical_cols, drop_first=True)\nX_test_encoded = pd.get_dummies(X_test_processed, columns=categorical_cols, drop_first=True)\n\n# Align columns to ensure both dataframes have the exact same features\nX_train_final, X_test_final = X_train_encoded.align(X_test_encoded, join='left', axis=1, fill_value=0)\n\n# Drop 'house_id' from the training set and remove any columns unique to the test set if alignment was outer/right\nX_train_final = X_train_final.drop('house_id', axis=1)\n\n# Prepare Test Set: Save house_id and drop it from features\nhouse_ids = X_test_final['house_id']\nX_test_final = X_test_final.drop('house_id', axis=1)\n# Handle potential NaN columns created during alignment (if test set was missing features)\nX_test_final = X_test_final.fillna(0) \n# Note: X_train_final will have NaN for columns missing in test, but since we align (join='left'),\n# only X_test_final will have NaN if train had extra columns, which we fill with 0.\n\n# --- 4. Model Fitting and Prediction ---\nlr = LinearRegression()\nlr.fit(X_train_final, y_train)\n\ny_pred = lr.predict(X_test_final)\n\n# --- 5. Final Output Creation ---\nbase_result = pd.DataFrame({\n    'house_id': house_ids,\n    'price': y_pred\n})\n\n\nprint(\"Successfully created 'base_result' with reduced feature set.\")","outputsMetadata":{"0":{"height":185,"type":"stream"}}},"id":"96496c59-fdd4-4683-9884-551ad93b788f","cell_type":"code","execution_count":163,"outputs":[{"output_type":"stream","name":"stdout","text":"Successfully created 'base_result' with reduced feature set.\n"}]},{"source":"# Task 5\n\nFit a comparison model to predict the sale price of a house.\n\n 1. Fit your model using the data contained in “train.csv” </br></br>\n\n 2. Use “validation.csv” to predict new values based on your model. You must return a dataframe named `compare_result`, that includes `house_id` and `price`. The price column must be your predicted values.","metadata":{},"id":"7c674c01-d6de-488d-b2e0-bc3bbf87def6","cell_type":"markdown"},{"source":"# Use this cell to write your code for Task 5\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\n\n# --- Data Loading ---\ndf_train_com = pd.read_csv('train.csv')\ndf_test_com = pd.read_csv('validation.csv')\n\n# --- 1. Separate Target Variable ---\ny_train_com = df_train_com['sale_price']\nX_train_com = df_train_com.drop('sale_price', axis=1)\n\n# --- 2. Feature Engineering: Handle sale_date (The Fix) ---\n\ndef engineer_date_features(df):\n    # Convert to datetime object first (Errors='coerce' handles invalid dates)\n    df['sale_date'] = pd.to_datetime(df['sale_date'], errors='coerce')\n    \n    # Extract numerical features\n    df['sale_year'] = df['sale_date'].dt.year\n    df['sale_month'] = df['sale_date'].dt.month\n    \n    # Extract categorical feature (Day of Week)\n    df['sale_day_of_week'] = df['sale_date'].dt.day_name()\n    \n    # DROP the original high-cardinality 'sale_date' column\n    df = df.drop('sale_date', axis=1)\n    return df\n\nX_train_processed = engineer_date_features(X_train_com)\nX_test_processed = engineer_date_features(df_test_com.copy()) # Use a copy of df_test\n\n# --- 3. Handle Remaining Categorical Variables ---\n# Remaining categorical columns: 'city', 'house_type', and the new 'sale_day_of_week'\ncategorical_cols = ['city', 'house_type', 'sale_day_of_week']\n\n# Apply One-Hot Encoding to both training and test sets\nX_train_encoded_com = pd.get_dummies(X_train_processed, columns=categorical_cols, drop_first=True)\nX_test_encoded_com = pd.get_dummies(X_test_processed, columns=categorical_cols, drop_first=True)\n\n# Align columns to ensure both dataframes have the exact same features\nX_train_final_com, X_test_final_com = X_train_encoded_com.align(X_test_encoded_com, join='left', axis=1, fill_value=0)\n\n# Drop 'house_id' from the training set and remove any columns unique to the test set if alignment was outer/right\nX_train_final_com = X_train_final_com.drop('house_id', axis=1)\n\n# Prepare Test Set: Save house_id and drop it from features\nhouse_ids_com = X_test_final_com['house_id']\nX_test_final_com = X_test_final_com.drop('house_id', axis=1)\n# Handle potential NaN columns created during alignment (if test set was missing features)\nX_test_final_com = X_test_final_com.fillna(0) \n# Note: X_train_final will have NaN for columns missing in test, but since we align (join='left'),\n# only X_test_final will have NaN if train had extra columns, which we fill with 0.\n\n# --- 4. Model Fitting and Prediction ---\nrf = RandomForestRegressor(n_estimators = 39, max_depth = 7, random_state=9)\nrf.fit(X_train_final_com, y_train)\n\ny_pred_com = rf.predict(X_test_final_com)\n\n# --- 5. Final Output Creation ---\ncompare_result = pd.DataFrame({\n    'house_id': house_ids_com,\n    'price': y_pred_com\n})\n\n\nprint(\"Successfully created 'compare_result' with reduced feature set.\")\n","metadata":{"executionCancelledAt":null,"executionTime":260,"lastExecutedAt":1764502824878,"lastExecutedByKernel":"52b7a7b8-c015-4ab4-a1fa-cd1e14fbe8a6","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Use this cell to write your code for Task 5\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\n\n# --- Data Loading ---\ndf_train_com = pd.read_csv('train.csv')\ndf_test_com = pd.read_csv('validation.csv')\n\n# --- 1. Separate Target Variable ---\ny_train_com = df_train_com['sale_price']\nX_train_com = df_train_com.drop('sale_price', axis=1)\n\n# --- 2. Feature Engineering: Handle sale_date (The Fix) ---\n\ndef engineer_date_features(df):\n    # Convert to datetime object first (Errors='coerce' handles invalid dates)\n    df['sale_date'] = pd.to_datetime(df['sale_date'], errors='coerce')\n    \n    # Extract numerical features\n    df['sale_year'] = df['sale_date'].dt.year\n    df['sale_month'] = df['sale_date'].dt.month\n    \n    # Extract categorical feature (Day of Week)\n    df['sale_day_of_week'] = df['sale_date'].dt.day_name()\n    \n    # DROP the original high-cardinality 'sale_date' column\n    df = df.drop('sale_date', axis=1)\n    return df\n\nX_train_processed = engineer_date_features(X_train_com)\nX_test_processed = engineer_date_features(df_test_com.copy()) # Use a copy of df_test\n\n# --- 3. Handle Remaining Categorical Variables ---\n# Remaining categorical columns: 'city', 'house_type', and the new 'sale_day_of_week'\ncategorical_cols = ['city', 'house_type', 'sale_day_of_week']\n\n# Apply One-Hot Encoding to both training and test sets\nX_train_encoded_com = pd.get_dummies(X_train_processed, columns=categorical_cols, drop_first=True)\nX_test_encoded_com = pd.get_dummies(X_test_processed, columns=categorical_cols, drop_first=True)\n\n# Align columns to ensure both dataframes have the exact same features\nX_train_final_com, X_test_final_com = X_train_encoded_com.align(X_test_encoded_com, join='left', axis=1, fill_value=0)\n\n# Drop 'house_id' from the training set and remove any columns unique to the test set if alignment was outer/right\nX_train_final_com = X_train_final_com.drop('house_id', axis=1)\n\n# Prepare Test Set: Save house_id and drop it from features\nhouse_ids_com = X_test_final_com['house_id']\nX_test_final_com = X_test_final_com.drop('house_id', axis=1)\n# Handle potential NaN columns created during alignment (if test set was missing features)\nX_test_final_com = X_test_final_com.fillna(0) \n# Note: X_train_final will have NaN for columns missing in test, but since we align (join='left'),\n# only X_test_final will have NaN if train had extra columns, which we fill with 0.\n\n# --- 4. Model Fitting and Prediction ---\nrf = RandomForestRegressor(n_estimators = 39, max_depth = 7, random_state=9)\nrf.fit(X_train_final_com, y_train)\n\ny_pred_com = rf.predict(X_test_final_com)\n\n# --- 5. Final Output Creation ---\ncompare_result = pd.DataFrame({\n    'house_id': house_ids_com,\n    'price': y_pred_com\n})\n\n\nprint(\"Successfully created 'compare_result' with reduced feature set.\")\n","outputsMetadata":{"0":{"height":38,"type":"stream"},"1":{"height":550,"type":"dataFrame","tableState":{"customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"80ba7767-e9fe-497a-8c15-b01d1431d7a8","nodeType":"const"}}}}},"id":"538ffb3d-4008-49b6-9876-7831e025f5a4","cell_type":"code","execution_count":164,"outputs":[{"output_type":"stream","name":"stdout","text":"Successfully created 'compare_result' with reduced feature set.\n"}]},{"source":"from sklearn.model_selection import RandomizedSearchCV\nimport numpy as np\nparam_dist = {'n_estimators': np.arange(1,101,1),\n          'max_depth':np.arange(1,11,1)}\ncv = RandomizedSearchCV(rf,param_distributions=param_dist,cv=5, random_state=9)\ncv.fit(X_train_final,y_train)\n# Print the tuned parameters and score\nprint(\"Tuned Random Forest Regressor Parameters: {}\".format(cv.best_params_))\nprint(\"Tuned Random Forest Regressor Best Accuracy Score: {}\".format(cv.best_score_))\n","metadata":{"executionCancelledAt":null,"executionTime":4602,"lastExecutedAt":1764502829480,"lastExecutedByKernel":"52b7a7b8-c015-4ab4-a1fa-cd1e14fbe8a6","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from sklearn.model_selection import RandomizedSearchCV\nimport numpy as np\nparam_dist = {'n_estimators': np.arange(1,101,1),\n          'max_depth':np.arange(1,11,1)}\ncv = RandomizedSearchCV(rf,param_distributions=param_dist,cv=5, random_state=9)\ncv.fit(X_train_final,y_train)\n# Print the tuned parameters and score\nprint(\"Tuned Random Forest Regressor Parameters: {}\".format(cv.best_params_))\nprint(\"Tuned Random Forest Regressor Best Accuracy Score: {}\".format(cv.best_score_))\n","outputsMetadata":{"0":{"height":59,"type":"stream"}}},"cell_type":"code","id":"779ea276-be0e-4f6d-ada0-7861102e7430","outputs":[{"output_type":"stream","name":"stdout","text":"Tuned Random Forest Regressor Parameters: {'n_estimators': 39, 'max_depth': 7}\nTuned Random Forest Regressor Best Accuracy Score: 0.9838515043684236\n"}],"execution_count":165},{"source":"from sklearn.model_selection import train_test_split\ndf_split = pd.read_csv('house_sales.csv')\nX = df_split.drop(\"sale_price\",axis=1)\ny = df_split['sale_price']\nX_train_check, X_test_check, y_train_check, y_test_check = train_test_split(X,y, test_size = 0.2,random_state=9)\nfrom sklearn.metrics import mean_squared_error \n\nmse = mean_squared_error(y_test_check,y_pred)\nrmse = mse**(1/2)\nrmse","metadata":{"executionCancelledAt":null,"executionTime":50,"lastExecutedAt":1764502829530,"lastExecutedByKernel":"52b7a7b8-c015-4ab4-a1fa-cd1e14fbe8a6","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from sklearn.model_selection import train_test_split\ndf_split = pd.read_csv('house_sales.csv')\nX = df_split.drop(\"sale_price\",axis=1)\ny = df_split['sale_price']\nX_train_check, X_test_check, y_train_check, y_test_check = train_test_split(X,y, test_size = 0.2,random_state=9)\nfrom sklearn.metrics import mean_squared_error \n\nmse = mean_squared_error(y_test_check,y_pred)\nrmse = mse**(1/2)\nrmse"},"cell_type":"code","id":"6afecb99-016e-476a-a582-e29e1737c0b0","outputs":[{"output_type":"execute_result","data":{"text/plain":"164657.2079166194"},"metadata":{},"execution_count":166}],"execution_count":166}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataCamp Workspace"},"nbformat":4,"nbformat_minor":5}